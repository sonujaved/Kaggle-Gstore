{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport scipy\n##import pandas_profiling\nimport tldextract\n\nimport matplotlib\nimport matplotlib.pyplot as plt # for plotting\nimport seaborn as sns # for making plots with seaborn\n\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport category_encoders as ce\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\n\nimport warnings\n#import imblearn\nwarnings.filterwarnings(\"ignore\")\nimport gc\nimport time\nimport json\nfrom pandas.io.json import json_normalize\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['sample_submission_v2.csv', 'test_v2.csv', 'train_v2.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "956c04cb7bdc6b6091a50e0d2d7176eb39153c2d"
      },
      "cell_type": "code",
      "source": "####################################################################################\n#  Date :- 17/09/2018\n#  Description :- Reusable Functions\n#  Name :- Javed Sheikh\n####################################################################################\n\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\n\ndef one_hot_encoder(data, nan_as_category = True):\n    original_columns = list(data.columns)\n    categorical_columns = [col for col in data.columns \\\n                           if not pd.api.types.is_numeric_dtype(data[col].dtype)]\n    for c in categorical_columns:\n        if nan_as_category:\n            data[c].fillna('NaN', inplace = True)\n        values = list(data[c].unique())\n        for v in values:\n            data[str(c) + '_' + str(v)] = (data[c] == v).astype(np.uint8)\n    data.drop(categorical_columns, axis = 1, inplace = True)\n    return data, [c for c in data.columns if c not in original_columns]\n\n#pandas_profiling.ProfileReport(application_train)\n\ndef missing_data(data):\n    total = data.isnull().sum().sort_values(ascending = False)\n    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n\n\ndef bar_plot_data(data,dataset):\n    temp = dataset[data].value_counts()\n    df = pd.DataFrame({'labels': temp.index,\n                   'values': temp.values\n                  })\n    plt.figure(figsize = (20,5))\n    plt.title('Application loans repayed - train dataset')\n    sns.barplot(x = 'labels', y=\"values\", data=df)\n    plt.show()\n\n    \n#Binning:\ndef binning(col, cut_points, labels=None):\n  #Define min and max values:\n  minval = col.min()\n  maxval = col.max()\n\n\n  #create list by adding min and max to cut_points\n  break_points = [minval] + cut_points + [maxval]\n\n  #if no labels provided, use default labels 0 ... (n-1)\n  if not labels:\n    labels = range(len(cut_points)+1)\n\n  #Binning using cut function of pandas\n  colBin = pd.cut(col,bins=break_points,labels=labels,include_lowest=True)\n  return colBin\n  \n\n  # function to obtain Categorical Features\ndef _get_categorical_features(df):\n    feats = [col for col in list(df.columns) if df[col].dtype == 'object']\n    return feats\n\n# function to factorize categorical features\ndef _factorize_categoricals(df, cats):\n    for col in cats:\n        df[col], _ = pd.factorize(df[col])\n    return df \n\n# function to create dummy variables of categorical features\ndef _get_dummies(df, cats):\n    for col in cats:\n        df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n    return df\n\nimport gc\ngc.enable()\nfeatures = ['channelGrouping', 'date', 'fullVisitorId', 'visitId',\\\n       'visitNumber', 'visitStartTime', 'device.browser',\\\n       'device.deviceCategory', 'device.isMobile', 'device.operatingSystem',\\\n       'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\\\n       'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\\\n       'geoNetwork.subContinent', 'totals.bounces', 'totals.hits',\\\n       'totals.newVisits', 'totals.pageviews', 'totals.transactionRevenue',\\\n       'trafficSource.adContent', 'trafficSource.campaign',\\\n       'trafficSource.isTrueDirect', 'trafficSource.keyword',\\\n       'trafficSource.medium', 'trafficSource.referralPath',\\\n       'trafficSource.source']\n",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4aa59a0fe22300b78e1bd8e6a930863be8c7b736"
      },
      "cell_type": "code",
      "source": "def load_df(csv_path='../input/train_v2.csv'):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    ans = pd.DataFrame()\n    dfs = pd.read_csv(csv_path, sep=',',\n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                    chunksize = 100000)\n    for df in dfs:\n        df.reset_index(drop = True,inplace = True)\n        for column in JSON_COLUMNS:\n            column_as_df = json_normalize(df[column])\n            column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n            df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n\n        print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n        use_df = df[features]\n        del df\n        gc.collect()\n        ans = pd.concat([ans, use_df], axis = 0).reset_index(drop = True)\n        print(ans.shape)\n    return ans\n\ntrain = load_df()\ntrain.shape",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Loaded train_v2.csv. Shape: (100000, 59)\n(100000, 29)\nLoaded train_v2.csv. Shape: (100000, 60)\n(200000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(300000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(400000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(500000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(600000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(700000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(800000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(900000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(1000000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(1100000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(1200000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(1300000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(1400000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(1500000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(1600000, 29)\nLoaded train_v2.csv. Shape: (100000, 59)\n(1700000, 29)\nLoaded train_v2.csv. Shape: (8337, 59)\n(1708337, 29)\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "(1708337, 29)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "21f6c63fabc3fac409b82a2d8e5336d22f599d35"
      },
      "cell_type": "code",
      "source": "####################################################################################\n#  Date :- 17/09/2018\n#  Description :- Reading Data\n#  Name :- Javed Sheikh\n####################################################################################\n\n##train_df = load_df(\"../input/train_v2.csv\")\ntest_df = load_df(\"../input/test_v2.csv\")",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Loaded test_v2.csv. Shape: (100000, 59)\n(100000, 29)\nLoaded test_v2.csv. Shape: (100000, 59)\n(200000, 29)\nLoaded test_v2.csv. Shape: (100000, 59)\n(300000, 29)\nLoaded test_v2.csv. Shape: (100000, 59)\n(400000, 29)\nLoaded test_v2.csv. Shape: (1589, 59)\n(401589, 29)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e5ed42d843fcfb9a59a558ea55dd8095671120f"
      },
      "cell_type": "code",
      "source": "train_df = train\ndel train\ngc.collect()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "a85e94d99dd57686e2f5080279cc17772ffce16a"
      },
      "cell_type": "code",
      "source": "test_df.columns.isin(train_df.columns)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fc4417856bddc933edf56bedb39e92f584e3dfd1"
      },
      "cell_type": "code",
      "source": "\ntrain_df['totals.transactionRevenue'] = train_df['totals.transactionRevenue'].fillna(0).astype(float)\n\nplt.figure(figsize=(15,15))\nfor i, binwidth in enumerate([1, 2, 3, 4]):\n    # Set up the plot\n    ax = plt.subplot(2, 2, i + 1)\n    # Draw the plot\n    ax.hist(np.log1p(train_df.loc[train_df['totals.transactionRevenue'] > 0,'totals.transactionRevenue']), \n            bins = int(180/binwidth)\n            ,color = 'Green'\n            ,edgecolor = 'white'\n           )\n    # Title and labels\n    ax.set_title('Histogram with Binwidth = %d' % binwidth, size = 30)\n    ax.set_xlabel('Target Revenue', size = 22)\n    ax.set_ylabel('Count', size= 22)\nplt.tight_layout()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3bb69072276eb40c3c7c7591f2b814ccb4831346"
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(12,6))\nsns.distplot((train_df.loc[train_df['totals.transactionRevenue'] > 0,'totals.transactionRevenue'])\n             ,hist=True\n             ,kde=True\n             ,bins=100\n             ,color = 'darkblue'\n             ,hist_kws={'edgecolor':'white'}\n             ,kde_kws={'linewidth': 4}\n            )\n\nplt.figure(figsize=(12,6))\nsns.distplot(np.log1p(train_df.loc[train_df['totals.transactionRevenue'] > 0,'totals.transactionRevenue'])\n             ,hist=True\n             ,kde=True\n             ,bins=100\n             ,color = 'Green'\n             ,hist_kws={'edgecolor':'white'}\n             ,kde_kws={'linewidth': 4}\n            )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8fe1af6f6a3572a8129b58fd5e9eb52cdb23372d"
      },
      "cell_type": "code",
      "source": "train_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f9957ef91771261760d30300b1e8097bbf0ba6d6"
      },
      "cell_type": "markdown",
      "source": "**Merging Dataset**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83acbcd3facf59625dd209b454124e5c5108bc13",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "train_df.columns.difference(test_df.columns)\n#train_df.drop('trafficSource.campaignCode', axis = 1,inplace=True)\ntrain_df['totals.transactionRevenue'] = np.log1p(train_df['totals.transactionRevenue'].fillna(0).astype(float))\n\n#Flaging Test / train set\ntest_df['is_train'] = 0\ntrain_df['is_train'] = 1\ntest_df['is_test'] = 1\ntrain_df['is_test'] = 0\n\n###Target Variables\nY = train_df['totals.transactionRevenue']\ntrain = train_df.drop(['totals.transactionRevenue'], axis = 1)\ntest =  test_df\n\n# Merge train and test\ndata = pd.concat([train, test], axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11259912fd85de7b0b1c83ef126865b7a663b7fd"
      },
      "cell_type": "code",
      "source": "data['trafficSource.adContent'] = data['trafficSource.adContent'].replace({'/':''}, regex=True).astype(str)\ndata['trafficSource.adContent'] = data['trafficSource.adContent'].replace({'}':''}, regex=True)\ndata['trafficSource.adContent'] = data['trafficSource.adContent'].replace({'{KeyWord:':''}, regex=True)\n## Replacing Missing values\ndata['trafficSource.adContent'] = data['trafficSource.adContent'].fillna('Unknown')\ndata['trafficSource.isTrueDirect'] = data['trafficSource.isTrueDirect'].fillna('False')\ndata['trafficSource.referralPath'] = data['trafficSource.referralPath'].fillna('/')\ndata['trafficSource.keyword'] = data['trafficSource.keyword'].fillna('(not provided)')\ndata['totals.bounces'] = data['totals.bounces'].fillna(0).astype(int)\ndata['totals.newVisits'] = data['totals.newVisits'].fillna(0).astype(int)\ndata['totals.pageviews'] = data['totals.pageviews'].fillna(0).astype(int)\ndata['totals.transactionRevenue'] = data['totals.transactionRevenue'].fillna(0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8db6ed7c20f1f07ec2139d22542cfb3c35c09a66"
      },
      "cell_type": "code",
      "source": "missing_data(data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4822827acdb2bdc3d289641fe0a6c0cd88085d3e"
      },
      "cell_type": "code",
      "source": "import category_encoders",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "6b1580b356858392f3fcd27ea587bc7df06f57c4"
      },
      "cell_type": "code",
      "source": "#########################################\n## Cleaning the URL's\n#########################################\nno_fetch_extract = tldextract.TLDExtract(suffix_list_urls=None)\n## Removing the numbers and \":\" if any\ndata['trafficSource.source_mod'] = data['trafficSource.source'].str.replace('\\d+', '').str.replace(':', '')\n## Use tldextract lib to clean the Source URL\ndata['Domain'] = data['trafficSource.source_mod'].apply(lambda x: no_fetch_extract(x).domain)\ndata['suffix'] = data['trafficSource.source_mod'].apply(lambda x: no_fetch_extract(x).suffix)\ndata['trafficSource.source'] = np.where(data['Domain'] == '', data['suffix'], data['Domain'])\n## Drop temporory columns\ndata.drop(['trafficSource.source_mod','Domain','suffix'], axis=1,inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dcc11dfdda567ba716d15371fb1ea7fd852e2edf"
      },
      "cell_type": "code",
      "source": "MAP_DICT={\n'Chrome':'Chrome',\n'Firefox':'Firefox',\n'UC Browser':'UCBrowser',\n'Internet Explorer':'InternetExplorer',\n'Safari':'Safari',\n'Edge':'InternetExplorer',\n'Opera Mini':'Opera',\n'Opera':'Opera',\n'BlackBerry':'BlackBerry',\n'Safari (in-app)':'Safari',\n'Coc Coc':'CocCoc',\n'Mozilla Compatible Agent':'Firefox',\n'ADM':'Android',\n'MRCHROME':'Chrome',\n'Amazon Silk':'Amazon',\n'YaBrowser':'YaBrowser',\n'Android Webview':'Android',\n'Puffin':'Puffin',\n'Nokia Browser':'Nokia',\n'Maxthon':'Maxthon',\n'Nintendo Browser':'Nintendo',\n'Android Browser':'Android',\n'Lunascape':'Others',\n'IE with Chrome Frame':'InternetExplorer',\n'ThumbSniper':'Others',\n'LYF_LS_4002_12':'Others',\n'Mozilla':'Firefox',\n'osee2unifiedRelease':'Others',\n'NokiaE52-1':'Nokia',\n'Iron':'Iron',\n'[Use default User-agent string] LIVRENPOCHE':'Others',\n'(not set)':'Others',\n'LYF_LS_4002_11':'Others',\n'M5':'M5',\n'Android Runtime':'Android',\n'Apple-iPhone7C2':'Safari',\n'SeaMonkey':'SeaMonkey',\n'Konqueror':'Others',\n'Seznam':'Seznam',\n'Changa 99695759':'Others',\n'no-ua':'Others',\n'MQQBrowser':'MQQ',\n'Nichrome':'Nichrome',\n'HTC802t_TD':'HTC',\n'DASH_JR_3G':'DASH',\n'DoCoMo':'DoCoMo',\n'subjectAgent: NoticiasBoom':'Others',\n'YE':'YE',\n'User Agent':'Others',\n'0':'Others',\n'Hisense M20-M_LTE':'Hisense',\n'Reddit':'Reddit',\n'TCL P500M':'TCL',\n'CSM Click':'CSM'}   \ndata['device.browser'] = data['device.browser'].map(MAP_DICT)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74dc923afcefb8bb51affd2c5aef240b8cc36c88"
      },
      "cell_type": "code",
      "source": "data['totals.bounces'] = data['totals.bounces'].astype(int)\ndata['totals.pageviews'] = data['totals.pageviews'].astype(int)\ndata['totals.newVisits'] = data['totals.newVisits'].astype(int)\ndata['totals.hits'] = data['totals.hits'].astype(int)\ndata['totals.Activity'] = np.log1p(data['totals.hits']  + data['totals.pageviews'] + data['totals.newVisits'] + data['totals.bounces'] )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bbd0e4800a9636698d4fbb1ee0720eb508524a51"
      },
      "cell_type": "code",
      "source": "bins = [0, 1, 2, 3, 4, 5, 6, 7,8]\nlabels = [1,2,3,4,5,6,7,8]\ndata['Level of Activity'] = pd.cut(data['totals.Activity'], bins=bins, labels=labels).astype(int)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8901ad8f4edf954c63e35e0936a12bb86cdeb69f"
      },
      "cell_type": "code",
      "source": "'''\n\n#data.drop('totals.visits', axis = 1,inplace=True)\n#data.drop('totals.pageviews', axis = 1,inplace=True)\n#data.drop('totals.newVisits', axis = 1,inplace=True)\n#data.drop('totals.hits', axis = 1,inplace=True)\n#data.drop('totals.bounces', axis = 1,inplace=True)\ndata.drop('totals.Activity', axis = 1,inplace=True)\ndata.drop(['trafficSource.adwordsClickInfo.gclId','geoNetwork.cityId','device.screenResolution',\n           'device.screenColors','device.operatingSystemVersion','device.mobileInputSelector',\n           'device.mobileDeviceModel','device.mobileDeviceMarketingName','device.mobileDeviceInfo',\n           'device.mobileDeviceBranding','device.language','device.flashVersion','device.browserVersion',\n           'device.browserSize','geoNetwork.latitude','geoNetwork.longitude']\n          , axis=1, inplace = True)\n\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c8c1a32c80bb09148ce4edc73e98ed43d14c1a7"
      },
      "cell_type": "code",
      "source": "data['date'] = data['date'].astype(str).apply(lambda x : x[:4] + \"-\" + x[4:6] + \"-\" + x[6:])\ndata['date'] = pd.to_datetime(data[\"date\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5f77b5e538e4348dbbaa6474b8b9c57de5f0e3ab"
      },
      "cell_type": "code",
      "source": "data['date_MM']  = data['date'].dt.month\ndata['date_D']   = data['date'].dt.day\ndata['date_Day'] = data['date'].dt.weekday\ndata['hour'] = data['date'].dt.hour\n\n\ndata[\"_id_incoherence\"] = pd.to_datetime(data['visitId'], unit='s') != data['date']\n\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\ncal = calendar()\nholidays = cal.holidays(start=data['date'].min(), end=data['date'].max())\ndata['is_holiday'] = data['date'].dt.date.astype('datetime64').isin(holidays)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "39ad8c497ca2c7fde4ec1f7d0b56796c410b5afc"
      },
      "cell_type": "code",
      "source": "  \n# remember visitId dublicates?\ndata[\"_visitId_dublicates\"] = data.visitId.map(data.visitId.value_counts())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d205785fd1f5e577c67148d9e1cd9531ccbf2df4",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "data['source.country'] = data['trafficSource.source'] + '_' + data['geoNetwork.country']\ndata['campaign.medium'] = data['trafficSource.campaign'] + '_' + data['trafficSource.medium']\ndata['browser.category'] = data['device.browser'] + '_' + data['device.deviceCategory']\ndata['browser.os'] = data['device.browser'] + '_' + data['device.operatingSystem']\ndata['device_deviceCategory_channelGrouping'] = data['device.deviceCategory'] + \"_\" + data['channelGrouping']\ndata['channelGrouping_browser'] = data['device.browser'] + \"_\" + data['channelGrouping']\ndata['channelGrouping_OS'] = data['device.operatingSystem'] + \"_\" + data['channelGrouping']\ndata['content.source'] = data['trafficSource.adContent'].astype(str) + \"_\" + data['source.country']\ndata['medium.source'] = data['trafficSource.medium'] + \"_\" + data['source.country']\ndata['visitStartTime_Time'] = pd.to_datetime(data['visitStartTime'], unit='s')\ndata['visitStartTime_HHMMSS'] = data['visitStartTime_Time'].astype(str).apply(lambda x:x.split(' ')[1])\ndata['visitStartTime_HH'] = data['visitStartTime_HHMMSS'].astype(str).apply(lambda x:x.split(':')[0])\ndata['visitStartTime_MM'] = data['visitStartTime_HHMMSS'].astype(str).apply(lambda x:x.split(':')[1])\ndata.drop(['visitStartTime_Time','visitId'], axis = 1,inplace=True)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0fa30954054a5244e76c55f8a948a5ce60b24213"
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(20,6))\ndata.loc[data['is_test'] == 1,'date'].value_counts().sort_index().plot(label=\"test\", color = \"#FFD700\")\ndata.loc[data['is_train'] == 1,'date'].value_counts().sort_index().plot(label=\"train\", color = \"#48D1CC\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0fb5e1581a78879835a2bcf14dae59291c8fde81"
      },
      "cell_type": "code",
      "source": "bins = [0,10,20,30,40,50,80,120,200,300,800]\nlabels = [1,2,3,4,5,6,7,8,9,10]\ndata['visitNumber'] = pd.cut(data['visitNumber'], bins=bins, labels=labels).astype(int)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a97ed07bf3567afa1fa3040179d13530e76280ba"
      },
      "cell_type": "code",
      "source": "data['nb_pageviews'] = data['date'].map( data[['date', 'totals.pageviews']].groupby('date')['totals.pageviews'].sum()    )\ndata['ratio_pageviews'] = data['totals.pageviews'] / data['nb_pageviews']\n\ndata['date'] = data['date'].astype(int)\ndata['visitStartTime_HH'] = data['visitStartTime_HH'].astype(int)\ndata['visitStartTime_MM'] = data['visitStartTime_MM'].astype(int)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "afb1f9a1514cd2693f403c4a3af053da7bcc5554"
      },
      "cell_type": "code",
      "source": "# get categorical features\ndata_cats = _get_categorical_features(data)\ndata_cats.remove('fullVisitorId')\n\n# factorize the categorical features from train and test data\ndata = _factorize_categoricals(data, data_cats)\ndata.drop(['date'], axis = 1,inplace=True)\ndata.reset_index(drop=True,inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3eed29700b74ae02063a2a81423c78fd0fb52be6"
      },
      "cell_type": "code",
      "source": "data_cats",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "058d6ad82263918f067991f8a9a1b762165da535"
      },
      "cell_type": "code",
      "source": "ignore_features = ['is_train', 'is_test']\nrelevant_features = [col for col in data.columns if col not in ignore_features]\ntrainX = data[data['is_train'] == 1][relevant_features]\ntestX = data[data['is_test'] == 1][relevant_features]\n\ntest_id = testX['fullVisitorId']\ntrain_id = trainX['fullVisitorId']\n\ntrainX.drop(['fullVisitorId'], axis = 1,inplace=True)\ntestX.drop(['fullVisitorId'], axis = 1,inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "582be9d52ca764a8e4fe155e2d09bc5ff274b295"
      },
      "cell_type": "code",
      "source": "x_train, x_val, y_train, y_val = train_test_split(trainX, Y, test_size=0.3, random_state=18)\nlgb_train = lgb.Dataset(data=x_train, label=y_train)\nlgb_eval = lgb.Dataset(data=x_val, label=y_val)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf28600519ddb6023eb363dda00334ed6cea08e1",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "\nparams = {\n        'learning_rate': 0.02,\n       # 'boosting_type':'gbdt',\n        'objective':'regression',\n        'metric':'rmse',\n        'num_leaves': 31,\n        'verbose': 1,\n        'bagging_fraction': 0.7934712636944741,\n        'feature_fraction': 0.686612409641711,\n        \"random_state\":42,\n        'max_depth': 5,\n        \"bagging_seed\" : 2019,\n        \"verbosity\" : -1,\n        \"bagging_frequency\" : 6,\n        'lambda_l2': 0.02085548700474218,\n        'lambda_l1': 0.004107624022751344,\n        'min_child_samples': 21,\n        'use_best_model':True,\n        'min_child_samples': 21\n         }\nmodel = lgb.train(params, \n                  lgb_train,\n                  categorical_feature=['channelGrouping', 'device.browser', 'device.deviceCategory', 'device.operatingSystem', 'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\n 'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region', 'geoNetwork.subContinent', 'totals.transactionRevenue', 'trafficSource.adContent', 'trafficSource.campaign', 'trafficSource.isTrueDirect',\n 'trafficSource.keyword', 'trafficSource.medium', 'trafficSource.referralPath', 'trafficSource.source', 'source.country', 'campaign.medium', 'browser.category', 'browser.os', 'device_deviceCategory_channelGrouping',\n 'channelGrouping_browser', 'channelGrouping_OS', 'content.source', 'medium.source', 'visitStartTime_HHMMSS'],\n                  valid_sets=lgb_eval, \n                  num_boost_round=10000,\n                  early_stopping_rounds=200 ,\n                  verbose_eval=400\n                 )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa6efc30ad92e09f58808607665f37ec2360ebe2"
      },
      "cell_type": "code",
      "source": "Data_T = lgb.Dataset(data=trainX, label=Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "edcdf2327d664fe4edd72a8e52fe68e41014518a"
      },
      "cell_type": "code",
      "source": "params = {\n        'learning_rate': 0.03,\n        'boosting_type':'gbdt',\n        'objective':'regression',\n        'metric':'rmse',\n        'num_leaves': 31,\n        'verbose': 1,\n        'bagging_fraction': 0.75,\n        'feature_fraction': 0.55,\n        \"random_state\":42,\n        'max_depth': 5,\n        \"bagging_seed\" : 2019,\n        \"verbosity\" : -1,\n        \"bagging_frequency\" : 6,\n        'lambda_l2': 0.5,\n        'lambda_l1': 0.5,\n        'min_child_samples': 100,\n        'use_best_model':True\n         }\nmodel_lgb = lgb.train(params, \n                  Data_T,\n                  categorical_feature=['channelGrouping', 'device.browser', 'device.deviceCategory', 'device.operatingSystem', 'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\n 'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region', 'geoNetwork.subContinent', 'totals.transactionRevenue', 'trafficSource.adContent', 'trafficSource.campaign', 'trafficSource.isTrueDirect',\n 'trafficSource.keyword', 'trafficSource.medium', 'trafficSource.referralPath', 'trafficSource.source', 'source.country', 'campaign.medium', 'browser.category', 'browser.os', 'device_deviceCategory_channelGrouping',\n 'channelGrouping_browser', 'channelGrouping_OS', 'content.source', 'medium.source', 'visitStartTime_HHMMSS'],\n                 # valid_sets=lgb_eval, \n                  num_boost_round=2000,\n                 # early_stopping_rounds=200, \n                  verbose_eval=400)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8aeb10d45927633fd2f32f89affee258db77f3b3"
      },
      "cell_type": "code",
      "source": "lgb.plot_importance(model_lgb, figsize=(12, 25), max_num_features=600)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9621d1ac2590ea51636cf6ef9100bbc302e660c2"
      },
      "cell_type": "code",
      "source": "lgb_preds = model.predict(testX)\nlgb_preds",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41cd2590b5f2cd56f008900e361fe4d1e1e8e745"
      },
      "cell_type": "code",
      "source": "#test_id = testX['fullVisitorId']  np.expm1(Y)\nsub_lgb = pd.DataFrame()\nsub_lgb['fullVisitorId'] = test_id\nsub_lgb['PredictedLogRevenue'] = lgb_preds\n#sub_lgb['PredictedLogRevenue'] = np.expm1(sub_lgb['PredictedLogRevenue'])\nsub_lgb = sub_lgb.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\n\n#sub_lgb.to_csv(\"lgb_baseline.csv\", index=False)\n\n\nsub_lgb.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5371ce35268e8e204f1de2b5f3b66a8497edba24"
      },
      "cell_type": "code",
      "source": "##https://www.kaggle.com/rahullalu/gstore-eda-lgbm-baseline-1-4260\n#READING SUMISSION FILE\n#DATASET VIEW\npath1=\"../input/\"\n\nsubmission=pd.read_csv(path1+'sample_submission_v2.csv')\n\n#CREATING JOIN BETWEEN PREDICTED DATA WITH SUBMISSION FILE\nsubmission=submission.join(sub_lgb.set_index('fullVisitorId'),on='fullVisitorId',lsuffix='_sub')\nsubmission.drop('PredictedLogRevenue_sub',axis=1,inplace=True)\n\n#HANDLING NaN IN CASE OF MISSING fullVisitorId\nsubmission.fillna(0,inplace=True)\n\n#SUBMITING FILE\nsubmission.to_csv('LGBM_submission.csv',index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}